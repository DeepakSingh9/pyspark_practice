{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "053e9b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f981456",
   "metadata": {},
   "outputs": [],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3660b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d72cf663",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = SparkSession.builder.appName('broadcast_accumulators').config('spark.driver.host','localhost').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "857ee32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = sc.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2589720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://localhost:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.2.4</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>broadcast_accumulators</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=broadcast_accumulators>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510ee7b7",
   "metadata": {},
   "source": [
    "WHAT IS THE DIFFERENCE BETWEEN SPARKSESSION AND SPARKCONTEXT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7740b34b",
   "metadata": {},
   "source": [
    "sparkSession: Introduced in spark2.0 it is a unified entry point to work with spark. Encapsulates the sparkContext ,sqlContext and HiveContext\n",
    "a) it has functionalities to work with DataFrames , DataSets and SQLAPIs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2129636",
   "metadata": {},
   "source": [
    "sparkContext: focuses mainly on low level APIs for RDD\n",
    "    * USED FOR OPERATIONS SUCH AS CREATING RDD AND MANAGING CLUSTER RESOURCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "883c9fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = spark.parallelize([1,2,4,5,5])\n",
    "# sparkContext is used to make RDDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f748373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at readRDDFromFile at PythonRDD.scala:274"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2838e59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 5, 5]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d10e142",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sc.createDataFrame([(1, \"Alice\"), (2, \"Bob\")], [\"id\", \"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87105032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, name: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14297aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "| id| name|\n",
      "+---+-----+\n",
      "|  1|Alice|\n",
      "|  2|  Bob|\n",
      "+---+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583d4cbf",
   "metadata": {},
   "source": [
    "# broadcast and accumulators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730c1e77",
   "metadata": {},
   "source": [
    "Broadcast: read-only large file/dataset that is distributed /broadcasted accross the nodes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9807f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "large_lookup_table ={\"apple\":\"fruit\",\"banana\":\"fruit\",\"maruti\":\"car\",\"broccolli\":\"vegetable\",\"chicken\":\"meat\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60565f35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(large_lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f91545b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "broadcast_var = spark.broadcast(large_lookup_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cb3de08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(word):\n",
    "    lookup_value = broadcast_var.value.get(word,\"unknown\")\n",
    "    return lookup_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d285e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "thing_list=[\"apple\",\"banana\",\"ball\",\"car\"]\n",
    "rdd_list = spark.parallelize(thing_list)\n",
    "classification = rdd_list.map(classify)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02234469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fruit', 'fruit', 'unknown', 'unknown']\n"
     ]
    }
   ],
   "source": [
    "print(classification.collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8bdfba3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fruit'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcast_var.value.get('apple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db77ef3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68a29d64",
   "metadata": {},
   "source": [
    "ACCUMULATORS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aea0083",
   "metadata": {},
   "source": [
    "Accumulators are shared , write-only variables that are used for aggregations of values accross tasks in a distributed environment.\n",
    "* They are primarily used to track global metrics or counters in a spark applications\n",
    "* while tasks can only update the value of accumulators , driver program can read it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0df0b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = [1,2,3,4,5,6,7]\n",
    "rdd = spark.parallelize(sample_data)\n",
    "\n",
    "# defince accumulator\n",
    "accum = spark.accumulator(0)\n",
    "rdd.foreach(lambda x: accum.add(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "debc509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n"
     ]
    }
   ],
   "source": [
    "print(accum.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7e78eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
